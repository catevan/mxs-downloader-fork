# -*- coding: utf-8 -*-
import streamlit as st
import requests
import os
import time
import re
import concurrent.futures
from bs4 import BeautifulSoup
from streamlit.runtime.scriptrunner import add_script_run_ctx

# --- åŸºç¡€é…ç½® ---
st.set_page_config(page_title="NAS æ¼«ç”»æ‰¹é‡ä¸‹è½½åŠ©æ‰‹", page_icon="ğŸ“š", layout="wide")

def clean_filename(filename):
    """æ¸…ç†éæ³•å­—ç¬¦ï¼Œå…¼å®¹ Win/Linux"""
    return re.sub(r'[\\/:*?"<>|]', '_', filename).strip()

def download_image(session, img_url, save_path, headers):
    """å•å›¾ä¸‹è½½é€»è¾‘ï¼ˆå¸¦é‡è¯•ï¼‰"""
    if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
        return True
    for _ in range(3):
        try:
            with session.get(img_url, stream=True, timeout=15, headers=headers) as r:
                if r.status_code == 200:
                    with open(save_path, 'wb') as f:
                        for chunk in r.iter_content(8192):
                            f.write(chunk)
                    return True
        except:
            time.sleep(1)
    return False

def download_chapter_task(session, chapter_url, chapter_idx, title, headers, img_threads):
    """å•ç« ä¸‹è½½ä»»åŠ¡"""
    save_dir = os.path.join("downloads", title, f"{chapter_idx:03d}")
    os.makedirs(save_dir, exist_ok=True)

    try:
        res = session.get(chapter_url, timeout=15, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        img_tags = soup.find_all('img', class_='lazy')
        img_urls = [img['data-original'] for img in img_tags if img.has_attr('data-original')]

        if not img_urls:
            return "No Images"

        with concurrent.futures.ThreadPoolExecutor(max_workers=img_threads) as executor:
            for i, url in enumerate(img_urls, 1):
                executor.submit(download_image, session, url, os.path.join(save_dir, f"{i:03d}.jpg"), headers)
        return "SUCCESS"
    except Exception as e:
        return str(e)

def process_single_manga(session, target_url, chapter_threads, img_threads):
    """è§£æå¹¶ä¸‹è½½å•æœ¬æ¼«ç”»çš„æ ¸å¿ƒé€»è¾‘"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
        'Referer': target_url
    }
    
    res = session.get(target_url, timeout=15, headers=headers)
    if res.status_code != 200:
        return None, "æ— æ³•è®¿é—®é“¾æ¥"
    
    soup = BeautifulSoup(res.text, 'html.parser')
    title_tag = soup.find('h1')
    if not title_tag:
        return None, "æ— æ³•è§£ææ ‡é¢˜"
    
    title = clean_filename(title_tag.text.strip())
    links = soup.select('ul#detail-list-select li a')
    chapter_urls = ["https://mxs12.cc" + a['href'] for a in links]
    
    if not chapter_urls:
        return title, "æœªæ‰¾åˆ°ç« èŠ‚"

    # æ‰§è¡Œç« èŠ‚å¹¶å‘ä¸‹è½½
    with concurrent.futures.ThreadPoolExecutor(max_workers=chapter_threads) as executor:
        futures = []
        for i, c_url in enumerate(chapter_urls, 1):
            f = executor.submit(download_chapter_task, session, c_url, i, title, headers, img_threads)
            add_script_run_ctx(f)
            futures.append(f)
        
        # å®æ—¶ç›‘æ§ç« èŠ‚å®Œæˆæƒ…å†µï¼ˆç»™è¿›åº¦æ¡ä½¿ç”¨ï¼‰
        yield title, len(chapter_urls), futures

# --- UI ç•Œé¢ ---
st.title("ğŸ“š NAS æ¼«ç”»å…¨è‡ªåŠ¨é‡‡é›†ç³»ç»Ÿ")
st.sidebar.header("å¹¶å‘å‚æ•°è®¾ç½®")
c_threads = st.sidebar.slider("åŒæ—¶ä¸‹è½½ç« èŠ‚æ•°", 1, 5, 2)
i_threads = st.sidebar.slider("æ¯ç« å¹¶å‘å›¾ç‰‡æ•°", 1, 10, 5)

tab1, tab2 = st.tabs(["ğŸ¯ å•æœ¬ä¸‹è½½", "æ‰¹é‡å…¨è‡ªåŠ¨é‡‡é›†"])

# --- æ¨¡å¼1ï¼šå•æœ¬ä¸‹è½½ ---
with tab1:
    url_input = st.text_input("è¾“å…¥æ¼«ç”»ç›®å½•é¡µé“¾æ¥", placeholder="https://mxs12.cc/book/900")
    if st.button("ç«‹å³å¼€å§‹"):
        if url_input:
            with requests.Session() as session:
                try:
                    gen = process_single_manga(session, url_input, c_threads, i_threads)
                    title, total_chapters, futures = next(gen)
                    st.write(f"æ­£åœ¨ä¸‹è½½ï¼š**{title}**")
                    pb = st.progress(0)
                    st_text = st.empty()
                    
                    done = 0
                    for f in concurrent.futures.as_completed(futures):
                        done += 1
                        pb.progress(done / total_chapters)
                        st_text.text(f"ç« èŠ‚è¿›åº¦: {done}/{total_chapters}")
                    st.success(f"ã€Š{title}ã€‹ä¸‹è½½å®Œæˆï¼")
                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

# --- æ¨¡å¼2ï¼šæ‰¹é‡é‡‡é›† ---
with tab2:
    st.warning("æé†’ï¼šæ‰¹é‡ä¸‹è½½ä¼šäº§ç”Ÿå¤§é‡è¯·æ±‚ï¼Œè¯·ç¡®ä¿ NAS ç©ºé—´å……è¶³ï¼Œå»ºè®®ç« èŠ‚å¹¶å‘ä¸è¦è¶…è¿‡ 2ã€‚")
    col1, col2 = st.columns(2)
    with col1:
        start_id = st.number_input("èµ·å§‹ ID (book/xxx)", value=900, min_value=1)
    with col2:
        end_id = st.number_input("ç»“æŸ ID", value=905, min_value=1)

    if st.button("å¯åŠ¨æ‰¹é‡é‡‡é›†ä»»åŠ¡"):
        if start_id > end_id:
            st.error("èµ·å§‹ ID å¿…é¡»å°äºç»“æŸ ID")
        else:
            main_pb = st.progress(0)
            main_status = st.empty()
            log_area = st.container()
            
            total_books = end_id - start_id + 1
            with requests.Session() as session:
                for idx, b_id in enumerate(range(start_id, end_id + 1)):
                    book_url = f"https://mxs12.cc/book/{b_id}"
                    main_status.markdown(f"**æ€»ä½“è¿›åº¦:** {idx}/{total_books} | **å½“å‰åˆ†æ:** ID {b_id}")
                    
                    try:
                        gen = process_single_manga(session, book_url, c_threads, i_threads)
                        title, total_chapters, futures = next(gen)
                        
                        with log_area:
                            st.write(f"ğŸš€ å¼€å§‹é‡‡é›† ID {b_id}: ã€Š{title}ã€‹...")
                            # æ‰¹é‡æ¨¡å¼ä¸‹ï¼Œç« èŠ‚å†…éƒ¨ä¸‹è½½ä½¿ç”¨é™é»˜ç­‰å¾…ï¼Œä¸é‡å¤æ˜¾ç¤ºå°è¿›åº¦æ¡
                            concurrent.futures.wait(futures)
                            st.write(f"âœ… ã€Š{title}ã€‹ä¸‹è½½æˆåŠŸã€‚")
                        
                    except StopIteration:
                        st.write(f"âš ï¸ ID {b_id} æ— æ•ˆæˆ–æ— å†…å®¹ï¼Œå·²è·³è¿‡ã€‚")
                    except Exception as e:
                        st.write(f"âŒ ID {b_id} å‡ºé”™: {e}")
                    
                    main_pb.progress((idx + 1) / total_books)
                    # é€‚å½“ä¼‘æ¯ï¼Œé˜²æ­¢è¢«å°
                    time.sleep(2)
            
            st.success("æ‰€æœ‰æ‰¹é‡ä»»åŠ¡å·²å®Œæˆï¼")